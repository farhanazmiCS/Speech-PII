{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejNwrT-YYssJ"
      },
      "source": [
        "# Forced Alignment with Vosk\n",
        "\n",
        "Originally, we evaluated the tagger's F1-score by simply using indices, which may be too penalising. In order to properly evaluate the performance of our PII identification pipeline, we would need to perform *forced alignment*, which aligns token-level transcripts into their corresponding timestamps in the audio files.\n",
        "\n",
        "For this, we shall be using *Vosk*, a toolkit which offers forced-alignment models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Change Directory to Root Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os \n",
        "\n",
        "os.chdir('..')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 489,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/farhan/Desktop/Research'"
            ]
          },
          "execution_count": 489,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper function for sorting the audio file names by ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 490,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve_key(file: str) -> int:\n",
        "    try:\n",
        "        # 3 digit\n",
        "        key = int(file[2:5])\n",
        "    except ValueError:\n",
        "        # 1 digit\n",
        "        if file[3] == '.':\n",
        "            key = int(file[2])\n",
        "        else:\n",
        "            key = int(file[2:4])\n",
        "    return key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper function to embed the entities within the transcripts (given a dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 491,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def insert_entity_tags_to_df(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Inserts entity boundary tags into the 'text' column based on 'entities',\n",
        "    and adds a new column 'tagged_text' with the result.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Must contain 'text' and 'entities' columns.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Same DataFrame with an additional 'tagged_text' column.\n",
        "    \"\"\"\n",
        "    def insert_tags(row):\n",
        "        text = row[\"text\"]\n",
        "        entities = row[\"entities\"]\n",
        "\n",
        "        # Sort entities in reverse order of start index to avoid offset issues\n",
        "        entities_sorted = sorted(entities, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        for start, end, label in entities_sorted:\n",
        "            tag_start = f\"[{label}_START]\"\n",
        "            tag_end = f\"[{label}_END]\"\n",
        "            text = text[:end] + tag_end + text[end:]\n",
        "            text = text[:start] + tag_start + text[start:]\n",
        "        \n",
        "        return text\n",
        "\n",
        "    df = df.copy()\n",
        "    df[\"tagged_text\"] = df.apply(insert_tags, axis=1)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper function to unify whitespaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 492,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def unify_whitespace(s):\n",
        "    \"\"\"\n",
        "    - Unify multiple spaces into one space across the text.\n",
        "    - Ensure exactly one space after [XXX_START] and before [XXX_END].\n",
        "    - Ensure one space after [XXX_END] if missing.\n",
        "    - Ensure one space before [XXX_START] if missing.\n",
        "    \"\"\"\n",
        "    if not isinstance(s, str):\n",
        "        return s\n",
        "\n",
        "    # Step 1: unify all whitespace\n",
        "    s = re.sub(r'\\s+', ' ', s.strip())\n",
        "\n",
        "    # Step 2: ensure space after [XXX_START] and before [XXX_END]\n",
        "    s = re.sub(r'(\\[\\w+_START\\])(\\S)', r'\\1 \\2', s)  # Add space after [START] if missing\n",
        "    s = re.sub(r'(\\S)(\\[\\w+_END\\])', r'\\1 \\2', s)    # Add space before [END] if missing\n",
        "\n",
        "    # Step 3: ensure space after [XXX_END] if missing\n",
        "    s = re.sub(r'(\\[\\w+_END\\])(\\S)', r'\\1 \\2', s)\n",
        "\n",
        "    # Step 4: ensure space before [XXX_START] if missing\n",
        "    s = re.sub(r'(\\S)(\\[\\w+_START\\])', r'\\1 \\2', s)  # Add space before [START] if missing\n",
        "\n",
        "    return s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper function to run Vosk forced-alignment model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 493,
      "metadata": {},
      "outputs": [],
      "source": [
        "from vosk import Model, KaldiRecognizer\n",
        "import soundfile as sf\n",
        "import json\n",
        "\n",
        "def run_vosk(audio_path: str, vosk_model: Model) -> list:\n",
        "    # Load audio\n",
        "    audio_data, sample_rate = sf.read(audio_path)\n",
        "    \n",
        "    # Prepare recognizer\n",
        "    rec = KaldiRecognizer(vosk_model, sample_rate)\n",
        "    rec.SetWords(True)\n",
        "    \n",
        "    if audio_data.ndim > 1:\n",
        "        audio_data = audio_data.mean(axis=1)  # Stereo to mono\n",
        "\n",
        "    pcm_data = (audio_data * 32767).astype(\"int16\").tobytes()\n",
        "\n",
        "    rec.AcceptWaveform(pcm_data)\n",
        "    result = json.loads(rec.FinalResult())\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper function to align reference Whisper-generated transcript to forced-alignment model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 682,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "spelled_out_numbers = {\n",
        "    'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4', 'five': '5',\n",
        "    'six': '6', 'seven': '7', 'eight': '8', 'nine': '9', 'ten': '10',\n",
        "    'eleven': '11', 'twelve': '12', 'thirteen': '13', 'fourteen': '14',\n",
        "    'fifteen': '15', 'sixteen': '16', 'seventeen': '17', 'eighteen': '18',\n",
        "    'nineteen': '19', 'twenty': '20', 'thirty': '30', 'forty': '40', 'fifty': '50',\n",
        "    'sixty': '60', 'seventy': '70', 'eighty': '80', 'ninety': '90',\n",
        "    'hundred': '100', 'thousand': '1000'\n",
        "}\n",
        "\n",
        "def clean_token(token):\n",
        "    \"\"\"Remove punctuation except '.' and lowercase.\"\"\"\n",
        "    allowed = '.'\n",
        "    punctuation_to_remove = ''.join(c for c in string.punctuation if c not in allowed)\n",
        "    return token.lower().translate(str.maketrans('', '', punctuation_to_remove))\n",
        "\n",
        "def process_entity_tokens(entity_tokens, char_tokens):\n",
        "    \"\"\"Prevent duplicates and extend entity tokens list.\"\"\"\n",
        "    for token in char_tokens:\n",
        "        if token not in entity_tokens:\n",
        "            entity_tokens.append(token)\n",
        "\n",
        "def align_transcript_with_vosk(vosk_words, transcript):\n",
        "    \"\"\"\n",
        "    Aligns a reference transcript with Vosk timestamps.\n",
        "    Handles [XXX_START]... [XXX_END] entities properly.\n",
        "    \"\"\"\n",
        "    tokens = re.findall(r'\\[.*?\\]|\\S+', transcript)  # Tokenize the transcript\n",
        "    aligned = []\n",
        "    vosk_idx = 0\n",
        "    current_entity = None\n",
        "    entity_tokens = []\n",
        "    entity_start_time = None\n",
        "    entity_end_time = None\n",
        "\n",
        "    entity_types_to_split = ['CREDIT_CARD', 'CAR_PLATE', 'BANK_ACCOUNT', 'NRIC', 'PHONE', 'PASSPORT_NUM']\n",
        "    \n",
        "    # Special case for emails: split on the dots (.) and @ but leave 'at' as-is\n",
        "    def split_email(token):\n",
        "        # Case 1: email with spaces (no @)\n",
        "        if '.' in token:\n",
        "            parts = re.split(r'([.])', token)\n",
        "            parts = [p for p in parts if p != '']\n",
        "            # print(parts)\n",
        "            return parts  # Remove any empty strings\n",
        "        # Case 2: email with @\n",
        "        elif '@' in token:\n",
        "            parts = re.split(r'([@.])', token)\n",
        "            parts = [p for p in parts if p != '']\n",
        "            # print(parts)\n",
        "            return parts\n",
        "        return [token]\n",
        "\n",
        "    i = 0  # Index to keep track of the current token in the list\n",
        "\n",
        "    while i < len(tokens):\n",
        "        token = tokens[i]\n",
        "\n",
        "        # print(f\"Current token: {token}\")\n",
        "\n",
        "        if token.endswith('_START]'):\n",
        "            # Start a new entity\n",
        "            current_entity = token.replace('[', '').replace(']', '').replace('_START', '')\n",
        "            entity_tokens = []\n",
        "            entity_start_time = None\n",
        "            entity_end_time = None\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        if token.endswith('_END]'):\n",
        "            # End the current entity\n",
        "            if current_entity:\n",
        "                # Flatten the entity and align with timestamps\n",
        "                flattened_entity = []\n",
        "                # print(f\"New entity tokens: {entity_tokens}\")\n",
        "                \n",
        "                for t in entity_tokens:\n",
        "                    # Clean the token\n",
        "                    clean_token_with_no_symbols = clean_token(t)\n",
        "                    \n",
        "                    # Check if the token is a spelled-out number\n",
        "                    if clean_token_with_no_symbols.lower() in spelled_out_numbers or current_entity == 'EMAIL':\n",
        "                        # If it's a spelled-out number, don't split it into characters\n",
        "                        flattened_entity.append(clean_token_with_no_symbols)\n",
        "                    else:\n",
        "                        # Otherwise, split the token into characters\n",
        "                        flattened_entity.extend(list(clean_token_with_no_symbols))\n",
        "                    \n",
        "                # Join the characters and align timestamps\n",
        "                aligned.append({\n",
        "                    \"word\": f\"[{current_entity}_START] {' '.join(flattened_entity)} [{current_entity}_END]\",\n",
        "                    \"start\": entity_start_time,\n",
        "                    \"end\": entity_end_time\n",
        "                })\n",
        "            current_entity = None\n",
        "            entity_tokens = []\n",
        "            entity_start_time = None\n",
        "            entity_end_time = None\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        clean_ref_word = clean_token(token)\n",
        "\n",
        "        if current_entity:\n",
        "            # Inside an entity, split the token into characters and modify the tokens list\n",
        "            if vosk_idx < len(vosk_words):\n",
        "                vosk_word = vosk_words[vosk_idx]['word']\n",
        "                if not entity_tokens:\n",
        "                    entity_start_time = vosk_words[vosk_idx]['start']\n",
        "                entity_end_time = vosk_words[vosk_idx]['end']\n",
        "\n",
        "                # Special handling for emails: split valid email format\n",
        "                if current_entity == 'EMAIL':\n",
        "                    char_tokens = split_email(token)  # Split email into parts\n",
        "                    tokens[i:i+1] = char_tokens  # Replace the current token with the split characters\n",
        "\n",
        "                    # Prevent duplicate tokens and extend entity tokens list\n",
        "                    process_entity_tokens(entity_tokens, char_tokens)\n",
        "                    print(f\"Entity tokens after email split: {entity_tokens}\")\n",
        "                # Inside the loop where you handle the token splitting:\n",
        "                elif current_entity in entity_types_to_split:\n",
        "                    clean_token_with_no_symbols = clean_token(token)  # Clean token\n",
        "\n",
        "                    # Check if the token is a spelled-out number\n",
        "                    if clean_token_with_no_symbols.lower() in spelled_out_numbers.keys():\n",
        "                        # If it's a spelled-out number, don't split it\n",
        "                        char_tokens = [clean_token_with_no_symbols]  # Keep the token as is\n",
        "                    else:\n",
        "                        # If it's not a spelled-out number, split it into characters\n",
        "                        char_tokens = list(clean_token_with_no_symbols)\n",
        "\n",
        "                    # Modify the tokens list in place by extending with the character tokens\n",
        "                    tokens[i:i+1] = char_tokens\n",
        "\n",
        "                    # Prevent duplicates and extend entity tokens list\n",
        "                    process_entity_tokens(entity_tokens, char_tokens)\n",
        "\n",
        "                    print(f\"Entity tokens after split: {entity_tokens}\")\n",
        "\n",
        "                vosk_idx += 1\n",
        "            else:\n",
        "                # No more Vosk words left (shouldn't happen usually)\n",
        "                entity_tokens.append(token)\n",
        "\n",
        "        else:\n",
        "            # Outside entity, normal matching\n",
        "            while vosk_idx < len(vosk_words):\n",
        "                clean_vosk_word = clean_token(vosk_words[vosk_idx]['word'])\n",
        "                aligned.append({\n",
        "                    \"word\": token,\n",
        "                    \"start\": vosk_words[vosk_idx]['start'],\n",
        "                    \"end\": vosk_words[vosk_idx]['end']\n",
        "                })\n",
        "                vosk_idx += 1\n",
        "                break\n",
        "\n",
        "        i += 1  # Move to the next token\n",
        "        # print(tokens)\n",
        "\n",
        "    return aligned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.chdir('..')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load batch 1 (150 samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The day before [DATE_START] yesterday, [DATE_E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>um my date of birth is uh second [DATE_START] ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>she handed over a crumpled piece of paper, the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aglio olio and err uh [CARDINAL_START] three t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[PERSON_START] Hong's [PERSON_END] email is [E...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  The day before [DATE_START] yesterday, [DATE_E...\n",
              "1  um my date of birth is uh second [DATE_START] ...\n",
              "2  she handed over a crumpled piece of paper, the...\n",
              "3  aglio olio and err uh [CARDINAL_START] three t...\n",
              "4  [PERSON_START] Hong's [PERSON_END] email is [E..."
            ]
          },
          "execution_count": 283,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "batch_one_ref = pd.read_json('data/true_data_150.jsonl', lines=True)\n",
        "batch_one_ref.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/Audio_Files_for_testing/id1.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/Audio_Files_for_testing/id2.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/Audio_Files_for_testing/id3.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/Audio_Files_for_testing/id4.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/Audio_Files_for_testing/id5.wav</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              file_name\n",
              "0  data/Audio_Files_for_testing/id1.wav\n",
              "1  data/Audio_Files_for_testing/id2.wav\n",
              "2  data/Audio_Files_for_testing/id3.wav\n",
              "3  data/Audio_Files_for_testing/id4.wav\n",
              "4  data/Audio_Files_for_testing/id5.wav"
            ]
          },
          "execution_count": 284,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "batch_one_files = sorted(os.listdir(\"data/Audio_Files_for_testing\"), key=retrieve_key)\n",
        "batch_one_files  = [f'data/Audio_Files_for_testing/{file}' for file in batch_one_files]\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "batch_one_df = pd.DataFrame(data=batch_one_files, columns=['file_name'])\n",
        "batch_one_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load batch 2 (350 samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>151</td>\n",
              "      <td>456 729103 8 is Kaifu Lee's DBS bank account, ...</td>\n",
              "      <td>[[0, 12, BANK_ACCOUNT]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>152</td>\n",
              "      <td>Jacob's OCBC bank account is 192-58462-3, and ...</td>\n",
              "      <td>[[29, 40, BANK_ACCOUNT]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>153</td>\n",
              "      <td>788 305194 2 is Zheng Qi's POSB bank account, ...</td>\n",
              "      <td>[[0, 12, BANK_ACCOUNT]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>154</td>\n",
              "      <td>Geetha's UOB bank account is 341-92741-9, and ...</td>\n",
              "      <td>[[29, 40, BANK_ACCOUNT]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>155</td>\n",
              "      <td>623 481057 6 is Ah Seng's Maybank account, and...</td>\n",
              "      <td>[[0, 12, BANK_ACCOUNT]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id                                               text  \\\n",
              "0  151  456 729103 8 is Kaifu Lee's DBS bank account, ...   \n",
              "1  152  Jacob's OCBC bank account is 192-58462-3, and ...   \n",
              "2  153  788 305194 2 is Zheng Qi's POSB bank account, ...   \n",
              "3  154  Geetha's UOB bank account is 341-92741-9, and ...   \n",
              "4  155  623 481057 6 is Ah Seng's Maybank account, and...   \n",
              "\n",
              "                   entities  \n",
              "0   [[0, 12, BANK_ACCOUNT]]  \n",
              "1  [[29, 40, BANK_ACCOUNT]]  \n",
              "2   [[0, 12, BANK_ACCOUNT]]  \n",
              "3  [[29, 40, BANK_ACCOUNT]]  \n",
              "4   [[0, 12, BANK_ACCOUNT]]  "
            ]
          },
          "execution_count": 285,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "batch_two_ref = pd.read_json('data/newtest_151_500_updated_TTS.jsonl', lines=True)\n",
        "batch_two_ref.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/newtest_151_500_updated_TTS/id151.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/newtest_151_500_updated_TTS/id152.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/newtest_151_500_updated_TTS/id153.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/newtest_151_500_updated_TTS/id154.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/newtest_151_500_updated_TTS/id155.wav</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    file_name\n",
              "0  data/newtest_151_500_updated_TTS/id151.wav\n",
              "1  data/newtest_151_500_updated_TTS/id152.wav\n",
              "2  data/newtest_151_500_updated_TTS/id153.wav\n",
              "3  data/newtest_151_500_updated_TTS/id154.wav\n",
              "4  data/newtest_151_500_updated_TTS/id155.wav"
            ]
          },
          "execution_count": 286,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "batch_two_files = sorted(os.listdir(\"data/newtest_151_500_updated_TTS\"), key=retrieve_key)\n",
        "batch_two_files  = [f'data/newtest_151_500_updated_TTS/{file}' for file in batch_two_files]\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "batch_two_df = pd.DataFrame(data=batch_two_files, columns=['file_name'])\n",
        "batch_two_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, for batch 2, the entities enclosed are not in the reference transcripts. As we are given the indices, we can write a helper function to include them within the transcripts. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocess transcripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_two_ref = insert_entity_tags_to_df(batch_two_ref)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>entities</th>\n",
              "      <th>tagged_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>151</td>\n",
              "      <td>456 729103 8 is Kaifu Lee's DBS bank account, ...</td>\n",
              "      <td>[[0, 12, BANK_ACCOUNT]]</td>\n",
              "      <td>[BANK_ACCOUNT_START]456 729103 8[BANK_ACCOUNT_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>152</td>\n",
              "      <td>Jacob's OCBC bank account is 192-58462-3, and ...</td>\n",
              "      <td>[[29, 40, BANK_ACCOUNT]]</td>\n",
              "      <td>Jacob's OCBC bank account is [BANK_ACCOUNT_STA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>153</td>\n",
              "      <td>788 305194 2 is Zheng Qi's POSB bank account, ...</td>\n",
              "      <td>[[0, 12, BANK_ACCOUNT]]</td>\n",
              "      <td>[BANK_ACCOUNT_START]788 305194 2[BANK_ACCOUNT_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>154</td>\n",
              "      <td>Geetha's UOB bank account is 341-92741-9, and ...</td>\n",
              "      <td>[[29, 40, BANK_ACCOUNT]]</td>\n",
              "      <td>Geetha's UOB bank account is [BANK_ACCOUNT_STA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>155</td>\n",
              "      <td>623 481057 6 is Ah Seng's Maybank account, and...</td>\n",
              "      <td>[[0, 12, BANK_ACCOUNT]]</td>\n",
              "      <td>[BANK_ACCOUNT_START]623 481057 6[BANK_ACCOUNT_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id                                               text  \\\n",
              "0  151  456 729103 8 is Kaifu Lee's DBS bank account, ...   \n",
              "1  152  Jacob's OCBC bank account is 192-58462-3, and ...   \n",
              "2  153  788 305194 2 is Zheng Qi's POSB bank account, ...   \n",
              "3  154  Geetha's UOB bank account is 341-92741-9, and ...   \n",
              "4  155  623 481057 6 is Ah Seng's Maybank account, and...   \n",
              "\n",
              "                   entities                                        tagged_text  \n",
              "0   [[0, 12, BANK_ACCOUNT]]  [BANK_ACCOUNT_START]456 729103 8[BANK_ACCOUNT_...  \n",
              "1  [[29, 40, BANK_ACCOUNT]]  Jacob's OCBC bank account is [BANK_ACCOUNT_STA...  \n",
              "2   [[0, 12, BANK_ACCOUNT]]  [BANK_ACCOUNT_START]788 305194 2[BANK_ACCOUNT_...  \n",
              "3  [[29, 40, BANK_ACCOUNT]]  Geetha's UOB bank account is [BANK_ACCOUNT_STA...  \n",
              "4   [[0, 12, BANK_ACCOUNT]]  [BANK_ACCOUNT_START]623 481057 6[BANK_ACCOUNT_...  "
            ]
          },
          "execution_count": 288,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_two_ref.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>entities</th>\n",
              "      <th>tagged_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>496</td>\n",
              "      <td>Patrick Loh boasting about his email patrick.l...</td>\n",
              "      <td>[[37, 60, EMAIL]]</td>\n",
              "      <td>Patrick Loh boasting about his email [EMAIL_ST...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>497</td>\n",
              "      <td>Jasmine Yeo got sian when someone spell her em...</td>\n",
              "      <td>[[50, 69, EMAIL]]</td>\n",
              "      <td>Jasmine Yeo got sian when someone spell her em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>498</td>\n",
              "      <td>Bobby Tan write his email bobby.tan@gmail.com ...</td>\n",
              "      <td>[[26, 45, EMAIL]]</td>\n",
              "      <td>Bobby Tan write his email [EMAIL_START]bobby.t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>499</td>\n",
              "      <td>Kamala Singh telling the IT guy her email kama...</td>\n",
              "      <td>[[42, 60, EMAIL]]</td>\n",
              "      <td>Kamala Singh telling the IT guy her email [EMA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>500</td>\n",
              "      <td>Raymond Koh say his email raymond.k@singnet.co...</td>\n",
              "      <td>[[26, 50, EMAIL]]</td>\n",
              "      <td>Raymond Koh say his email [EMAIL_START]raymond...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                               text  \\\n",
              "346  496  Patrick Loh boasting about his email patrick.l...   \n",
              "347  497  Jasmine Yeo got sian when someone spell her em...   \n",
              "348  498  Bobby Tan write his email bobby.tan@gmail.com ...   \n",
              "349  499  Kamala Singh telling the IT guy her email kama...   \n",
              "350  500  Raymond Koh say his email raymond.k@singnet.co...   \n",
              "\n",
              "              entities                                        tagged_text  \n",
              "346  [[37, 60, EMAIL]]  Patrick Loh boasting about his email [EMAIL_ST...  \n",
              "347  [[50, 69, EMAIL]]  Jasmine Yeo got sian when someone spell her em...  \n",
              "348  [[26, 45, EMAIL]]  Bobby Tan write his email [EMAIL_START]bobby.t...  \n",
              "349  [[42, 60, EMAIL]]  Kamala Singh telling the IT guy her email [EMA...  \n",
              "350  [[26, 50, EMAIL]]  Raymond Koh say his email [EMAIL_START]raymond...  "
            ]
          },
          "execution_count": 289,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_two_ref.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[BANK_ACCOUNT_START]456 729103 8[BANK_ACCOUNT_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jacob's OCBC bank account is [BANK_ACCOUNT_STA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[BANK_ACCOUNT_START]788 305194 2[BANK_ACCOUNT_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Geetha's UOB bank account is [BANK_ACCOUNT_STA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[BANK_ACCOUNT_START]623 481057 6[BANK_ACCOUNT_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  [BANK_ACCOUNT_START]456 729103 8[BANK_ACCOUNT_...\n",
              "1  Jacob's OCBC bank account is [BANK_ACCOUNT_STA...\n",
              "2  [BANK_ACCOUNT_START]788 305194 2[BANK_ACCOUNT_...\n",
              "3  Geetha's UOB bank account is [BANK_ACCOUNT_STA...\n",
              "4  [BANK_ACCOUNT_START]623 481057 6[BANK_ACCOUNT_..."
            ]
          },
          "execution_count": 290,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_two_ref = batch_two_ref.drop(columns=['entities', 'text', 'id'], axis=1)\n",
        "batch_two_ref.rename(columns={'tagged_text': 'text'}, inplace=True)\n",
        "batch_two_ref.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combine the datasets [Run this when dataset not combined yet]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set_ref = pd.concat([batch_one_ref, batch_two_ref], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The day before [DATE_START] yesterday, [DATE_E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>um my date of birth is uh second [DATE_START] ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>she handed over a crumpled piece of paper, the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aglio olio and err uh [CARDINAL_START] three t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[PERSON_START] Hong's [PERSON_END] email is [E...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  The day before [DATE_START] yesterday, [DATE_E...\n",
              "1  um my date of birth is uh second [DATE_START] ...\n",
              "2  she handed over a crumpled piece of paper, the...\n",
              "3  aglio olio and err uh [CARDINAL_START] three t...\n",
              "4  [PERSON_START] Hong's [PERSON_END] email is [E..."
            ]
          },
          "execution_count": 292,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_ref.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>Patrick Loh boasting about his email [EMAIL_ST...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>Jasmine Yeo got sian when someone spell her em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>Bobby Tan write his email [EMAIL_START]bobby.t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>Kamala Singh telling the IT guy her email [EMA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>Raymond Koh say his email [EMAIL_START]raymond...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text\n",
              "496  Patrick Loh boasting about his email [EMAIL_ST...\n",
              "497  Jasmine Yeo got sian when someone spell her em...\n",
              "498  Bobby Tan write his email [EMAIL_START]bobby.t...\n",
              "499  Kamala Singh telling the IT guy her email [EMA...\n",
              "500  Raymond Koh say his email [EMAIL_START]raymond..."
            ]
          },
          "execution_count": 293,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_ref.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set_ref['text'] = test_set_ref['text'].apply(unify_whitespace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set_ref.to_json('data/test_set_ref_all.jsonl', lines=True, orient='records')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the combined processed dataset [When already combined]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 495,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set_ref = pd.read_json('data/test_set_ref_all.jsonl', lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 496,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The day before [DATE_START] yesterday, [DATE_E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>um my date of birth is uh second [DATE_START] ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>she handed over a crumpled piece of paper, the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aglio olio and err uh [CARDINAL_START] three t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[PERSON_START] Hong's [PERSON_END] email is [E...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  The day before [DATE_START] yesterday, [DATE_E...\n",
              "1  um my date of birth is uh second [DATE_START] ...\n",
              "2  she handed over a crumpled piece of paper, the...\n",
              "3  aglio olio and err uh [CARDINAL_START] three t...\n",
              "4  [PERSON_START] Hong's [PERSON_END] email is [E..."
            ]
          },
          "execution_count": 496,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_ref.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 497,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>Patrick Loh boasting about his email [EMAIL_ST...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>Jasmine Yeo got sian when someone spell her em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>Bobby Tan write his email [EMAIL_START] bobby....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>Kamala Singh telling the IT guy her email [EMA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>Raymond Koh say his email [EMAIL_START] raymon...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text\n",
              "496  Patrick Loh boasting about his email [EMAIL_ST...\n",
              "497  Jasmine Yeo got sian when someone spell her em...\n",
              "498  Bobby Tan write his email [EMAIL_START] bobby....\n",
              "499  Kamala Singh telling the IT guy her email [EMA...\n",
              "500  Raymond Koh say his email [EMAIL_START] raymon..."
            ]
          },
          "execution_count": 497,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_ref.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the model (Vosk)\n",
        "\n",
        "Unfortunately, there are no current models that are tuned for Singaporean English (Singlish). As such, we shall use the `vosk-model-en-us-0.42-gigaspeech` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 498,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=8\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
            "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
            "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from models/vosk-model-en-us-0.42-gigaspeech/ivector/final.ie\n",
            "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
            "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:279) Loading HCLG from models/vosk-model-en-us-0.42-gigaspeech/graph/HCLG.fst\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:294) Loading words from models/vosk-model-en-us-0.42-gigaspeech/graph/words.txt\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo models/vosk-model-en-us-0.42-gigaspeech/graph/phones/word_boundary.int\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading subtract G.fst model from models/vosk-model-en-us-0.42-gigaspeech/rescore/G.fst\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:312) Loading CARPA model from models/vosk-model-en-us-0.42-gigaspeech/rescore/G.carpa\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:318) Loading RNNLM model from models/vosk-model-en-us-0.42-gigaspeech/rnnlm/final.raw\n"
          ]
        }
      ],
      "source": [
        "from vosk import Model, KaldiRecognizer\n",
        "import soundfile as sf\n",
        "import json\n",
        "\n",
        "# Load model (replace path with your model directory)\n",
        "model_path = \"models/vosk-model-en-us-0.42-gigaspeech\"\n",
        "model = Model(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Read Audio (With just one sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So here, several things are happening:\n",
        "\n",
        "1. We create a `KaldiRecognizer` instance and set `.SetWords()` to `True`, which means that we will get word-level timestamps.\n",
        "2. The `.AcceptWaveform()` method is used to process the waveform\n",
        "3. The `.FinalResult()` method is finally called to retrieve the word-level timestamps (transcribed from the Vosk Model - although with some innacurracies, as Vosk is not a full-fledged ASR model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test on one audio sample (Simple example with Name and Email PIIs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 499,
      "metadata": {},
      "outputs": [],
      "source": [
        "audio_path = \"data/Audio_Files_for_testing/id1.wav\"\n",
        "audio_data, sample_rate = sf.read(audio_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 500,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample = run_vosk(audio_path, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 501,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'result': [{'conf': 1.0, 'end': 0.69, 'start': 0.51, 'word': 'the'},\n",
              "  {'conf': 1.0, 'end': 0.87, 'start': 0.69, 'word': 'day'},\n",
              "  {'conf': 1.0, 'end': 1.2, 'start': 0.87, 'word': 'before'},\n",
              "  {'conf': 1.0, 'end': 1.68, 'start': 1.2, 'word': 'yesterday'},\n",
              "  {'conf': 0.558658, 'end': 2.04, 'start': 1.77, 'word': 'ram'},\n",
              "  {'conf': 1.0, 'end': 2.46, 'start': 2.04, 'word': 'received'},\n",
              "  {'conf': 1.0, 'end': 2.88, 'start': 2.49, 'word': 'another'},\n",
              "  {'conf': 1.0, 'end': 3.27, 'start': 2.94, 'word': 'email'},\n",
              "  {'conf': 1.0, 'end': 3.6, 'start': 3.27, 'word': 'from'},\n",
              "  {'conf': 0.974828, 'end': 4.111625, 'start': 3.69, 'word': 'ahri'},\n",
              "  {'conf': 0.54586, 'end': 4.236342, 'start': 4.111625, 'word': 'and'},\n",
              "  {'conf': 0.276569, 'end': 4.53, 'start': 4.236342, 'word': 'envoy'},\n",
              "  {'conf': 1.0, 'end': 4.74, 'start': 4.546376, 'word': 'it'},\n",
              "  {'conf': 1.0, 'end': 5.16, 'start': 4.95, 'word': 'club'},\n",
              "  {'conf': 1.0, 'end': 5.43, 'start': 5.16, 'word': 'dot'},\n",
              "  {'conf': 0.605647, 'end': 5.64, 'start': 5.46, 'word': 's'},\n",
              "  {'conf': 0.927367, 'end': 5.94, 'start': 5.64, 'word': 'g'}],\n",
              " 'text': 'the day before yesterday ram received another email from ahri and envoy it club dot s g'}"
            ]
          },
          "execution_count": 501,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reference Transcript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 502,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The day before [DATE_START] yesterday, [DATE_END] [PERSON_START] Ram [PERSON_END] received another email from [EMAIL_START] r e m y at outlook dot sg [EMAIL_END]'"
            ]
          },
          "execution_count": 502,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_ref['text'].iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Align method usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 562,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['r']\n",
            "['e']\n",
            "['m']\n",
            "['y']\n",
            "['at']\n",
            "['outlook']\n",
            "['dot']\n",
            "['sg']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'word': 'The', 'start': 0.51, 'end': 0.69},\n",
              " {'word': 'day', 'start': 0.69, 'end': 0.87},\n",
              " {'word': 'before', 'start': 0.87, 'end': 1.2},\n",
              " {'word': '[DATE_START] y e s t e r d a y [DATE_END]',\n",
              "  'start': 1.2,\n",
              "  'end': 1.68},\n",
              " {'word': '[PERSON_START] r a m [PERSON_END]', 'start': 1.77, 'end': 2.04},\n",
              " {'word': 'received', 'start': 2.04, 'end': 2.46},\n",
              " {'word': 'another', 'start': 2.49, 'end': 2.88},\n",
              " {'word': 'email', 'start': 2.94, 'end': 3.27},\n",
              " {'word': 'from', 'start': 3.27, 'end': 3.6},\n",
              " {'word': '[EMAIL_START] r e m y a t o u t l o o k d o t s g [EMAIL_END]',\n",
              "  'start': 3.69,\n",
              "  'end': 5.94}]"
            ]
          },
          "execution_count": 562,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "align_transcript_with_vosk(sample['result'], test_set_ref['text'].iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test on one audio sample (Numerical PIIs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 684,
      "metadata": {},
      "outputs": [],
      "source": [
        "audio_path = \"data/Audio_Files_for_testing/id52.wav\"\n",
        "audio_data, sample_rate = sf.read(audio_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 685,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample2 = run_vosk(audio_path, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 686,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'result': [{'conf': 0.633794, 'end': 1.17, 'start': 0.66, 'word': 'ok'},\n",
              "  {'conf': 0.292178, 'end': 1.8, 'start': 1.5, 'word': 'ah'},\n",
              "  {'conf': 1.0, 'end': 2.55, 'start': 2.01, 'word': 'contact'},\n",
              "  {'conf': 1.0, 'end': 3.0, 'start': 2.55, 'word': 'number'},\n",
              "  {'conf': 1.0, 'end': 3.48, 'start': 3.12, 'word': 'just'},\n",
              "  {'conf': 1.0, 'end': 3.75, 'start': 3.48, 'word': 'put'},\n",
              "  {'conf': 1.0, 'end': 4.38, 'start': 3.93, 'word': 'nine'},\n",
              "  {'conf': 1.0, 'end': 4.71, 'start': 4.41, 'word': 'eight'},\n",
              "  {'conf': 1.0, 'end': 5.07, 'start': 4.71, 'word': 'four'},\n",
              "  {'conf': 1.0, 'end': 5.43, 'start': 5.07, 'word': 'zero'},\n",
              "  {'conf': 1.0, 'end': 5.85, 'start': 5.43, 'word': 'six'},\n",
              "  {'conf': 0.995706, 'end': 6.18, 'start': 5.85, 'word': 'four'},\n",
              "  {'conf': 1.0, 'end': 6.48, 'start': 6.18, 'word': 'one'},\n",
              "  {'conf': 1.0, 'end': 6.75, 'start': 6.51, 'word': 'three'}],\n",
              " 'text': 'ok ah contact number just put nine eight four zero six four one three'}"
            ]
          },
          "execution_count": 686,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 687,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'okay uh contact number just put [PHONE_START] Nine eight four zero six four one three [PHONE_END]'"
            ]
          },
          "execution_count": 687,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_ref['text'].iloc[51]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Force align"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "credit_card, car_plate, bank_account, nric, phone, passport_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 688,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entity tokens after split: ['nine']\n",
            "Entity tokens after split: ['nine', 'eight']\n",
            "Entity tokens after split: ['nine', 'eight', 'four']\n",
            "Entity tokens after split: ['nine', 'eight', 'four', 'zero']\n",
            "Entity tokens after split: ['nine', 'eight', 'four', 'zero', 'six']\n",
            "Entity tokens after split: ['nine', 'eight', 'four', 'zero', 'six']\n",
            "Entity tokens after split: ['nine', 'eight', 'four', 'zero', 'six', 'one']\n",
            "Entity tokens after split: ['nine', 'eight', 'four', 'zero', 'six', 'one', 'three']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'word': 'okay', 'start': 0.66, 'end': 1.17},\n",
              " {'word': 'uh', 'start': 1.5, 'end': 1.8},\n",
              " {'word': 'contact', 'start': 2.01, 'end': 2.55},\n",
              " {'word': 'number', 'start': 2.55, 'end': 3.0},\n",
              " {'word': 'just', 'start': 3.12, 'end': 3.48},\n",
              " {'word': 'put', 'start': 3.48, 'end': 3.75},\n",
              " {'word': '[PHONE_START] nine eight four zero six one three [PHONE_END]',\n",
              "  'start': 3.93,\n",
              "  'end': 6.75}]"
            ]
          },
          "execution_count": 688,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "align_transcript_with_vosk(sample2['result'], test_set_ref['text'].iloc[51])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Heuristics Description:\n",
        "\n",
        "Forced-alignment heuristics are necessary because:\n",
        "- The **Vosk model** may tokenize words differently compared to the reference transcript, especially for structured data like emails, phone numbers, and other PIIs (Personally Identifiable Information).\n",
        "- **PII structures vary greatly** (e.g., \"rendy.tan@hotmail.com\" vs \"rendy . tan at hotmail dot com\"), and simple word-to-word alignment would fail.\n",
        "- To achieve robust alignment and accurate timestamp mapping, **manual control** over token splitting and flattening is required based on the entity type.\n",
        "\n",
        "These heuristics ensure that:\n",
        "- Common free-text is aligned naturally,\n",
        "- Structured PII is broken down appropriately for correct timestamp boundary matching.\n",
        "\n",
        "#### 1. Outside of Entity Boundaries (General Case)\n",
        "\n",
        "- Tokens are aligned **as-is** with Vosk words.\n",
        "- No special splitting is done.\n",
        "- Regular cleaning (punctuation removal except for `\".\"`) is applied when matching.\n",
        "- **Example**:\n",
        "  - Input Transcript: `\"reach me at\"`\n",
        "  - Tokens: `[\"reach\", \"me\", \"at\"]`\n",
        "  - Aligned directly without splitting.\n",
        "\n",
        "#### 2. Inside Entity Boundaries (e.g., [EMAIL_START], [PHONE_START], etc.)\n",
        "\n",
        "- Special handling is done based on the entity type.\n",
        "\n",
        "##### (A) EMAIL Entity (`current_entity == 'EMAIL'`)\n",
        "\n",
        "- Split tokens based on `\".\"` and `\"@\"` separators.\n",
        "- Words like `\"at\"` are **left intact**.\n",
        "- **Example**:\n",
        "  - Input: `\"rendy.tan@hotmail.com\"`\n",
        "  - Split into: `[\"rendy\", \".\", \"tan\", \"@\", \"hotmail\", \".\", \"com\"]`\n",
        "\n",
        "##### (B) Other Entity Types (`CREDIT_CARD`, `CAR_PLATE`, `BANK_ACCOUNT`, `NRIC`, `PHONE`, `PASSPORT_NUM`)\n",
        "\n",
        "- **If the token is a spelled-out number** (checked against a dictionary):\n",
        "  - **Do not split**; keep the word as a single token.\n",
        "  - **Example**:\n",
        "    - Input: `\"eight\"`\n",
        "    - Output: `[\"eight\"]`\n",
        "\n",
        "- **If the token is pure digits** (e.g., numbers like `\"98005331\"`):\n",
        "  - **Split** into **individual characters**.\n",
        "  - **Example**:\n",
        "    - Input: `\"98005331\"`\n",
        "    - Output: `[\"9\", \"8\", \"0\", \"0\", \"5\", \"3\", \"3\", \"1\"]`\n",
        "\n",
        "- **If the token is a mix of letters and numbers** (e.g., `\"AB1234X\"`):\n",
        "  - **Split** into **individual characters** as well.\n",
        "  - **Example**:\n",
        "    - Input: `\"AB1234X\"`\n",
        "    - Output: `[\"A\", \"B\", \"1\", \"2\", \"3\", \"4\", \"X\"]`\n",
        "\n",
        "#### 3. When Flattening Entity Tokens (Before Final Alignment)\n",
        "\n",
        "- After all splitting:\n",
        "  - **Spelled-out numbers** (like `\"eight\"`) and **email parts** (like `\"hotmail\"`) are **kept whole**.\n",
        "  - Other tokens (numbers, single characters) appear **character-by-character**.\n",
        "\n",
        "- **Flattening Examples**:\n",
        "  - Tokens: `[\"eight\", \"5\", \"0\"]`\n",
        "    - Final output: `\"eight 5 0\"`\n",
        "  \n",
        "  - Tokens: `[\"hotmail\", \".\", \"com\"]`\n",
        "    - Final output: `\"hotmail . com\"`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Read Audio (All 500 samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [Archived]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import tempfile\n",
        "from pydub import AudioSegment\n",
        "from vosk import Model, KaldiRecognizer\n",
        "model_path = \"vosk-model-en-us-0.42-gigaspeech\" #model_new\"\n",
        "model = Model(model_path)\n",
        "def align_audio_with_text(audio_path, transcription):\n",
        "    audio = AudioSegment.from_wav(audio_path)\n",
        "    recognizer = KaldiRecognizer(model, audio.frame_rate)\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as temp_wav:\n",
        "        temp_wav_path = temp_wav.name\n",
        "        audio.export(temp_wav_path, format=\"wav\")\n",
        "    results = []\n",
        "    try:\n",
        "        with open(temp_wav_path, \"rb\") as wf:\n",
        "            wf.read(44)\n",
        "            recognizer.SetWords(True)\n",
        "            while True:\n",
        "                data = wf.read(4000)\n",
        "                if len(data) == 0:\n",
        "                    break\n",
        "                if recognizer.AcceptWaveform(data):\n",
        "                    results.append(json.loads(recognizer.Result()))\n",
        "            results.append(json.loads(recognizer.FinalResult()))\n",
        "    finally:\n",
        "        if os.path.exists(temp_wav_path):\n",
        "            os.remove(temp_wav_path)\n",
        "    words = []\n",
        "    for result in results:\n",
        "        if 'result' in result:\n",
        "            for word in result['result']:\n",
        "                words.append(word)\n",
        "    aligned_segments = []\n",
        "    for word in words:\n",
        "        aligned_segments.append({\n",
        "            \"start\": word[\"start\"],\n",
        "            \"end\": word[\"end\"],\n",
        "            \"word\": word[\"word\"]\n",
        "        })\n",
        "    return aligned_segments\n",
        "\n",
        "audio_dir = \"/content/drive/MyDrive/Share/Research/speechNER/finetune/Audio_Files_for_testing\"\n",
        "transcription_file = \"/content/drive/MyDrive/Share/Research/speechNER/Alignement_data/Text_with_ids_temp_preprocessed.jsonl\"\n",
        "output_file = \"/content/drive/MyDrive/Share/Research/speechNER/Alignement_data/tr_aligned_data_new.jsonl\"\n",
        "with open(transcription_file, 'r') as f:\n",
        "    transcriptions = [json.loads(line) for line in f]\n",
        "aligned_data = []\n",
        "for item in transcriptions:\n",
        "    audio_path = f\"{audio_dir}/id{item['id']}.wav\"\n",
        "    aligned_transcription = align_audio_with_text(audio_path, item['text'])\n",
        "    aligned_data.append({\n",
        "        \"id\": item['id'],\n",
        "        \"text\": item['text'],\n",
        "        \"align\": aligned_transcription\n",
        "    })\n",
        "with open(output_file, 'w') as f:\n",
        "    for item in aligned_data:\n",
        "        f.write(json.dumps(item) + '\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
