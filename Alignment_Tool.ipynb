{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejNwrT-YYssJ"
      },
      "source": [
        "# Forced Alignment with Vosk\n",
        "\n",
        "Originally, we evaluated the tagger's F1-score by simply using indices, which may be too penalising. In order to properly evaluate the performance of our PII identification pipeline, we would need to perform *forced alignment*, which aligns token-level transcripts into their corresponding timestamps in the audio files.\n",
        "\n",
        "For this, we shall be using *Vosk*, a toolkit which offers forced-alignment models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Change Directory to Root Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os \n",
        "\n",
        "os.chdir('..')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/farhan/Desktop/Research'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper function for sorting the audio file names by ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve_key(file: str) -> int:\n",
        "    try:\n",
        "        # 3 digit\n",
        "        key = int(file[2:5])\n",
        "    except ValueError:\n",
        "        # 1 digit\n",
        "        if file[3] == '.':\n",
        "            key = int(file[2])\n",
        "        else:\n",
        "            key = int(file[2:4])\n",
        "    return key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper function to embed the entities within the transcripts (given a dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def insert_entity_tags_to_df(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Inserts entity boundary tags into the 'text' column based on 'entities',\n",
        "    and adds a new column 'tagged_text' with the result.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Must contain 'text' and 'entities' columns.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Same DataFrame with an additional 'tagged_text' column.\n",
        "    \"\"\"\n",
        "    def insert_tags(row):\n",
        "        text = row[\"text\"]\n",
        "        entities = row[\"entities\"]\n",
        "\n",
        "        # Sort entities in reverse order of start index to avoid offset issues\n",
        "        entities_sorted = sorted(entities, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        for start, end, label in entities_sorted:\n",
        "            tag_start = f\"[{label}_START]\"\n",
        "            tag_end = f\"[{label}_END]\"\n",
        "            text = text[:end] + tag_end + text[end:]\n",
        "            text = text[:start] + tag_start + text[start:]\n",
        "        \n",
        "        return text\n",
        "\n",
        "    df = df.copy()\n",
        "    df[\"tagged_text\"] = df.apply(insert_tags, axis=1)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper function to unify whitespaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def unify_whitespace(s):\n",
        "    \"\"\"\n",
        "    - Unify multiple spaces into one space across the text.\n",
        "    - Ensure exactly one space after [XXX_START] and before [XXX_END].\n",
        "    - Ensure one space after [XXX_END] if missing.\n",
        "    - Ensure one space before [XXX_START] if missing.\n",
        "    \"\"\"\n",
        "    if not isinstance(s, str):\n",
        "        return s\n",
        "\n",
        "    # Step 1: unify all whitespace\n",
        "    s = re.sub(r'\\s+', ' ', s.strip())\n",
        "\n",
        "    # Step 2: ensure space after [XXX_START] and before [XXX_END]\n",
        "    s = re.sub(r'(\\[\\w+_START\\])(\\S)', r'\\1 \\2', s)  # Add space after [START] if missing\n",
        "    s = re.sub(r'(\\S)(\\[\\w+_END\\])', r'\\1 \\2', s)    # Add space before [END] if missing\n",
        "\n",
        "    # Step 3: ensure space after [XXX_END] if missing\n",
        "    s = re.sub(r'(\\[\\w+_END\\])(\\S)', r'\\1 \\2', s)\n",
        "\n",
        "    # Step 4: ensure space before [XXX_START] if missing\n",
        "    s = re.sub(r'(\\S)(\\[\\w+_START\\])', r'\\1 \\2', s)  # Add space before [START] if missing\n",
        "\n",
        "    return s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper function to run Vosk forced-alignment model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from vosk import Model, KaldiRecognizer\n",
        "import soundfile as sf\n",
        "import json\n",
        "\n",
        "def run_vosk(audio_path: str, vosk_model: Model) -> list:\n",
        "    # Load audio\n",
        "    audio_data, sample_rate = sf.read(audio_path)\n",
        "    \n",
        "    # Prepare recognizer\n",
        "    rec = KaldiRecognizer(vosk_model, sample_rate)\n",
        "    rec.SetWords(True)\n",
        "    \n",
        "    if audio_data.ndim > 1:\n",
        "        audio_data = audio_data.mean(axis=1)  # Stereo to mono\n",
        "\n",
        "    pcm_data = (audio_data * 32767).astype(\"int16\").tobytes()\n",
        "\n",
        "    rec.AcceptWaveform(pcm_data)\n",
        "    result = json.loads(rec.FinalResult())\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper function to align reference Whisper-generated transcript to forced-alignment model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 462,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def clean_token(token):\n",
        "    \"\"\"Remove punctuation and lowercase.\"\"\"\n",
        "    return token.lower().translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "def align_transcript_with_vosk(vosk_words, transcript):\n",
        "    \"\"\"\n",
        "    Aligns a reference transcript with Vosk timestamps.\n",
        "    Handles [XXX_START]... [XXX_END] entities properly.\n",
        "    \"\"\"\n",
        "    tokens = re.findall(r'\\[.*?\\]|\\S+', transcript)  # Tokenize the transcript\n",
        "    aligned = []\n",
        "    vosk_idx = 0\n",
        "    current_entity = None\n",
        "    entity_tokens = []\n",
        "    entity_start_time = None\n",
        "    entity_end_time = None\n",
        "\n",
        "    entity_types_to_split = ['CREDIT_CARD', 'CAR_PLATE', 'BANK_ACCOUNT', 'NRIC', 'PHONE', 'PASSPORT_NUM']\n",
        "    \n",
        "    i = 0  # Index to keep track of the current token in the list\n",
        "\n",
        "    while i < len(tokens):\n",
        "        token = tokens[i]\n",
        "\n",
        "        print(f\"Current token: {token}\")\n",
        "\n",
        "        if token.endswith('_START]'):\n",
        "            # Start a new entity\n",
        "            current_entity = token.replace('[', '').replace(']', '').replace('_START', '')\n",
        "            entity_tokens = []\n",
        "            entity_start_time = None\n",
        "            entity_end_time = None\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        if token.endswith('_END]'):\n",
        "            # End the current entity\n",
        "            if current_entity:\n",
        "                # Flatten the entity and align with timestamps\n",
        "                flattened_entity = []\n",
        "                for t in entity_tokens:\n",
        "                    clean_token_with_no_symbols = clean_token(t)  # Clean token\n",
        "                    flattened_entity.extend(list(clean_token_with_no_symbols))  # Split into characters\n",
        "                # Join the characters and align timestamps\n",
        "                aligned.append({\n",
        "                    \"word\": f\"[{current_entity}_START] {' '.join(flattened_entity)} [{current_entity}_END]\",\n",
        "                    \"start\": entity_start_time,\n",
        "                    \"end\": entity_end_time\n",
        "                })\n",
        "            current_entity = None\n",
        "            entity_tokens = []\n",
        "            entity_start_time = None\n",
        "            entity_end_time = None\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        clean_ref_word = clean_token(token)\n",
        "\n",
        "        if current_entity:\n",
        "            # Inside an entity, split the token into characters and modify the tokens list\n",
        "            if vosk_idx < len(vosk_words):\n",
        "                vosk_word = vosk_words[vosk_idx]['word']\n",
        "                if not entity_tokens:\n",
        "                    entity_start_time = vosk_words[vosk_idx]['start']\n",
        "                entity_end_time = vosk_words[vosk_idx]['end']\n",
        "\n",
        "                # Only split tokens into characters if the entity is in the defined list\n",
        "                if current_entity in entity_types_to_split:\n",
        "                    clean_token_with_no_symbols = clean_token(token)  # Clean token\n",
        "                    char_tokens = list(clean_token_with_no_symbols)  # Split into characters\n",
        "\n",
        "                    # Modify the tokens list in place by extending with the character tokens\n",
        "                    tokens[i:i+1] = char_tokens  # Replace the current token with the split characters\n",
        "                    entity_tokens.extend(char_tokens)  # Add characters to entity tokens list\n",
        "                else:\n",
        "                    # If not a specified entity type, just add the token as is\n",
        "                    entity_tokens.append(token)\n",
        "\n",
        "                vosk_idx += 1\n",
        "            else:\n",
        "                # No more Vosk words left (shouldn't happen usually)\n",
        "                entity_tokens.append(token)\n",
        "\n",
        "        else:\n",
        "            # Outside entity, normal matching\n",
        "            while vosk_idx < len(vosk_words):\n",
        "                clean_vosk_word = clean_token(vosk_words[vosk_idx]['word'])\n",
        "                aligned.append({\n",
        "                    \"word\": token,\n",
        "                    \"start\": vosk_words[vosk_idx]['start'],\n",
        "                    \"end\": vosk_words[vosk_idx]['end']\n",
        "                })\n",
        "                vosk_idx += 1\n",
        "                break\n",
        "\n",
        "        i += 1  # Move to the next token\n",
        "\n",
        "    return aligned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.chdir('..')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load batch 1 (150 samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The day before [DATE_START] yesterday, [DATE_E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>um my date of birth is uh second [DATE_START] ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>she handed over a crumpled piece of paper, the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aglio olio and err uh [CARDINAL_START] three t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[PERSON_START] Hong's [PERSON_END] email is [E...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  The day before [DATE_START] yesterday, [DATE_E...\n",
              "1  um my date of birth is uh second [DATE_START] ...\n",
              "2  she handed over a crumpled piece of paper, the...\n",
              "3  aglio olio and err uh [CARDINAL_START] three t...\n",
              "4  [PERSON_START] Hong's [PERSON_END] email is [E..."
            ]
          },
          "execution_count": 283,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "batch_one_ref = pd.read_json('data/true_data_150.jsonl', lines=True)\n",
        "batch_one_ref.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/Audio_Files_for_testing/id1.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/Audio_Files_for_testing/id2.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/Audio_Files_for_testing/id3.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/Audio_Files_for_testing/id4.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/Audio_Files_for_testing/id5.wav</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              file_name\n",
              "0  data/Audio_Files_for_testing/id1.wav\n",
              "1  data/Audio_Files_for_testing/id2.wav\n",
              "2  data/Audio_Files_for_testing/id3.wav\n",
              "3  data/Audio_Files_for_testing/id4.wav\n",
              "4  data/Audio_Files_for_testing/id5.wav"
            ]
          },
          "execution_count": 284,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "batch_one_files = sorted(os.listdir(\"data/Audio_Files_for_testing\"), key=retrieve_key)\n",
        "batch_one_files  = [f'data/Audio_Files_for_testing/{file}' for file in batch_one_files]\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "batch_one_df = pd.DataFrame(data=batch_one_files, columns=['file_name'])\n",
        "batch_one_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load batch 2 (350 samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>151</td>\n",
              "      <td>456 729103 8 is Kaifu Lee's DBS bank account, ...</td>\n",
              "      <td>[[0, 12, BANK_ACCOUNT]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>152</td>\n",
              "      <td>Jacob's OCBC bank account is 192-58462-3, and ...</td>\n",
              "      <td>[[29, 40, BANK_ACCOUNT]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>153</td>\n",
              "      <td>788 305194 2 is Zheng Qi's POSB bank account, ...</td>\n",
              "      <td>[[0, 12, BANK_ACCOUNT]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>154</td>\n",
              "      <td>Geetha's UOB bank account is 341-92741-9, and ...</td>\n",
              "      <td>[[29, 40, BANK_ACCOUNT]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>155</td>\n",
              "      <td>623 481057 6 is Ah Seng's Maybank account, and...</td>\n",
              "      <td>[[0, 12, BANK_ACCOUNT]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id                                               text  \\\n",
              "0  151  456 729103 8 is Kaifu Lee's DBS bank account, ...   \n",
              "1  152  Jacob's OCBC bank account is 192-58462-3, and ...   \n",
              "2  153  788 305194 2 is Zheng Qi's POSB bank account, ...   \n",
              "3  154  Geetha's UOB bank account is 341-92741-9, and ...   \n",
              "4  155  623 481057 6 is Ah Seng's Maybank account, and...   \n",
              "\n",
              "                   entities  \n",
              "0   [[0, 12, BANK_ACCOUNT]]  \n",
              "1  [[29, 40, BANK_ACCOUNT]]  \n",
              "2   [[0, 12, BANK_ACCOUNT]]  \n",
              "3  [[29, 40, BANK_ACCOUNT]]  \n",
              "4   [[0, 12, BANK_ACCOUNT]]  "
            ]
          },
          "execution_count": 285,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "batch_two_ref = pd.read_json('data/newtest_151_500_updated_TTS.jsonl', lines=True)\n",
        "batch_two_ref.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/newtest_151_500_updated_TTS/id151.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/newtest_151_500_updated_TTS/id152.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/newtest_151_500_updated_TTS/id153.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/newtest_151_500_updated_TTS/id154.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/newtest_151_500_updated_TTS/id155.wav</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    file_name\n",
              "0  data/newtest_151_500_updated_TTS/id151.wav\n",
              "1  data/newtest_151_500_updated_TTS/id152.wav\n",
              "2  data/newtest_151_500_updated_TTS/id153.wav\n",
              "3  data/newtest_151_500_updated_TTS/id154.wav\n",
              "4  data/newtest_151_500_updated_TTS/id155.wav"
            ]
          },
          "execution_count": 286,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "batch_two_files = sorted(os.listdir(\"data/newtest_151_500_updated_TTS\"), key=retrieve_key)\n",
        "batch_two_files  = [f'data/newtest_151_500_updated_TTS/{file}' for file in batch_two_files]\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "batch_two_df = pd.DataFrame(data=batch_two_files, columns=['file_name'])\n",
        "batch_two_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, for batch 2, the entities enclosed are not in the reference transcripts. As we are given the indices, we can write a helper function to include them within the transcripts. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocess transcripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_two_ref = insert_entity_tags_to_df(batch_two_ref)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>entities</th>\n",
              "      <th>tagged_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>151</td>\n",
              "      <td>456 729103 8 is Kaifu Lee's DBS bank account, ...</td>\n",
              "      <td>[[0, 12, BANK_ACCOUNT]]</td>\n",
              "      <td>[BANK_ACCOUNT_START]456 729103 8[BANK_ACCOUNT_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>152</td>\n",
              "      <td>Jacob's OCBC bank account is 192-58462-3, and ...</td>\n",
              "      <td>[[29, 40, BANK_ACCOUNT]]</td>\n",
              "      <td>Jacob's OCBC bank account is [BANK_ACCOUNT_STA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>153</td>\n",
              "      <td>788 305194 2 is Zheng Qi's POSB bank account, ...</td>\n",
              "      <td>[[0, 12, BANK_ACCOUNT]]</td>\n",
              "      <td>[BANK_ACCOUNT_START]788 305194 2[BANK_ACCOUNT_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>154</td>\n",
              "      <td>Geetha's UOB bank account is 341-92741-9, and ...</td>\n",
              "      <td>[[29, 40, BANK_ACCOUNT]]</td>\n",
              "      <td>Geetha's UOB bank account is [BANK_ACCOUNT_STA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>155</td>\n",
              "      <td>623 481057 6 is Ah Seng's Maybank account, and...</td>\n",
              "      <td>[[0, 12, BANK_ACCOUNT]]</td>\n",
              "      <td>[BANK_ACCOUNT_START]623 481057 6[BANK_ACCOUNT_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id                                               text  \\\n",
              "0  151  456 729103 8 is Kaifu Lee's DBS bank account, ...   \n",
              "1  152  Jacob's OCBC bank account is 192-58462-3, and ...   \n",
              "2  153  788 305194 2 is Zheng Qi's POSB bank account, ...   \n",
              "3  154  Geetha's UOB bank account is 341-92741-9, and ...   \n",
              "4  155  623 481057 6 is Ah Seng's Maybank account, and...   \n",
              "\n",
              "                   entities                                        tagged_text  \n",
              "0   [[0, 12, BANK_ACCOUNT]]  [BANK_ACCOUNT_START]456 729103 8[BANK_ACCOUNT_...  \n",
              "1  [[29, 40, BANK_ACCOUNT]]  Jacob's OCBC bank account is [BANK_ACCOUNT_STA...  \n",
              "2   [[0, 12, BANK_ACCOUNT]]  [BANK_ACCOUNT_START]788 305194 2[BANK_ACCOUNT_...  \n",
              "3  [[29, 40, BANK_ACCOUNT]]  Geetha's UOB bank account is [BANK_ACCOUNT_STA...  \n",
              "4   [[0, 12, BANK_ACCOUNT]]  [BANK_ACCOUNT_START]623 481057 6[BANK_ACCOUNT_...  "
            ]
          },
          "execution_count": 288,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_two_ref.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>entities</th>\n",
              "      <th>tagged_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>496</td>\n",
              "      <td>Patrick Loh boasting about his email patrick.l...</td>\n",
              "      <td>[[37, 60, EMAIL]]</td>\n",
              "      <td>Patrick Loh boasting about his email [EMAIL_ST...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>497</td>\n",
              "      <td>Jasmine Yeo got sian when someone spell her em...</td>\n",
              "      <td>[[50, 69, EMAIL]]</td>\n",
              "      <td>Jasmine Yeo got sian when someone spell her em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>498</td>\n",
              "      <td>Bobby Tan write his email bobby.tan@gmail.com ...</td>\n",
              "      <td>[[26, 45, EMAIL]]</td>\n",
              "      <td>Bobby Tan write his email [EMAIL_START]bobby.t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>499</td>\n",
              "      <td>Kamala Singh telling the IT guy her email kama...</td>\n",
              "      <td>[[42, 60, EMAIL]]</td>\n",
              "      <td>Kamala Singh telling the IT guy her email [EMA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>500</td>\n",
              "      <td>Raymond Koh say his email raymond.k@singnet.co...</td>\n",
              "      <td>[[26, 50, EMAIL]]</td>\n",
              "      <td>Raymond Koh say his email [EMAIL_START]raymond...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                               text  \\\n",
              "346  496  Patrick Loh boasting about his email patrick.l...   \n",
              "347  497  Jasmine Yeo got sian when someone spell her em...   \n",
              "348  498  Bobby Tan write his email bobby.tan@gmail.com ...   \n",
              "349  499  Kamala Singh telling the IT guy her email kama...   \n",
              "350  500  Raymond Koh say his email raymond.k@singnet.co...   \n",
              "\n",
              "              entities                                        tagged_text  \n",
              "346  [[37, 60, EMAIL]]  Patrick Loh boasting about his email [EMAIL_ST...  \n",
              "347  [[50, 69, EMAIL]]  Jasmine Yeo got sian when someone spell her em...  \n",
              "348  [[26, 45, EMAIL]]  Bobby Tan write his email [EMAIL_START]bobby.t...  \n",
              "349  [[42, 60, EMAIL]]  Kamala Singh telling the IT guy her email [EMA...  \n",
              "350  [[26, 50, EMAIL]]  Raymond Koh say his email [EMAIL_START]raymond...  "
            ]
          },
          "execution_count": 289,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_two_ref.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[BANK_ACCOUNT_START]456 729103 8[BANK_ACCOUNT_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jacob's OCBC bank account is [BANK_ACCOUNT_STA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[BANK_ACCOUNT_START]788 305194 2[BANK_ACCOUNT_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Geetha's UOB bank account is [BANK_ACCOUNT_STA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[BANK_ACCOUNT_START]623 481057 6[BANK_ACCOUNT_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  [BANK_ACCOUNT_START]456 729103 8[BANK_ACCOUNT_...\n",
              "1  Jacob's OCBC bank account is [BANK_ACCOUNT_STA...\n",
              "2  [BANK_ACCOUNT_START]788 305194 2[BANK_ACCOUNT_...\n",
              "3  Geetha's UOB bank account is [BANK_ACCOUNT_STA...\n",
              "4  [BANK_ACCOUNT_START]623 481057 6[BANK_ACCOUNT_..."
            ]
          },
          "execution_count": 290,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_two_ref = batch_two_ref.drop(columns=['entities', 'text', 'id'], axis=1)\n",
        "batch_two_ref.rename(columns={'tagged_text': 'text'}, inplace=True)\n",
        "batch_two_ref.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combine the datasets [Run this when dataset not combined yet]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set_ref = pd.concat([batch_one_ref, batch_two_ref], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The day before [DATE_START] yesterday, [DATE_E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>um my date of birth is uh second [DATE_START] ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>she handed over a crumpled piece of paper, the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aglio olio and err uh [CARDINAL_START] three t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[PERSON_START] Hong's [PERSON_END] email is [E...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  The day before [DATE_START] yesterday, [DATE_E...\n",
              "1  um my date of birth is uh second [DATE_START] ...\n",
              "2  she handed over a crumpled piece of paper, the...\n",
              "3  aglio olio and err uh [CARDINAL_START] three t...\n",
              "4  [PERSON_START] Hong's [PERSON_END] email is [E..."
            ]
          },
          "execution_count": 292,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_ref.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>Patrick Loh boasting about his email [EMAIL_ST...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>Jasmine Yeo got sian when someone spell her em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>Bobby Tan write his email [EMAIL_START]bobby.t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>Kamala Singh telling the IT guy her email [EMA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>Raymond Koh say his email [EMAIL_START]raymond...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text\n",
              "496  Patrick Loh boasting about his email [EMAIL_ST...\n",
              "497  Jasmine Yeo got sian when someone spell her em...\n",
              "498  Bobby Tan write his email [EMAIL_START]bobby.t...\n",
              "499  Kamala Singh telling the IT guy her email [EMA...\n",
              "500  Raymond Koh say his email [EMAIL_START]raymond..."
            ]
          },
          "execution_count": 293,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_ref.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set_ref['text'] = test_set_ref['text'].apply(unify_whitespace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set_ref.to_json('data/test_set_ref_all.jsonl', lines=True, orient='records')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the combined processed dataset [When already combined]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set_ref = pd.read_json('data/test_set_ref_all.jsonl', lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The day before [DATE_START] yesterday, [DATE_E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>um my date of birth is uh second [DATE_START] ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>she handed over a crumpled piece of paper, the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aglio olio and err uh [CARDINAL_START] three t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[PERSON_START] Hong's [PERSON_END] email is [E...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  The day before [DATE_START] yesterday, [DATE_E...\n",
              "1  um my date of birth is uh second [DATE_START] ...\n",
              "2  she handed over a crumpled piece of paper, the...\n",
              "3  aglio olio and err uh [CARDINAL_START] three t...\n",
              "4  [PERSON_START] Hong's [PERSON_END] email is [E..."
            ]
          },
          "execution_count": 297,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_ref.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>Patrick Loh boasting about his email [EMAIL_ST...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>Jasmine Yeo got sian when someone spell her em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>Bobby Tan write his email [EMAIL_START] bobby....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>Kamala Singh telling the IT guy her email [EMA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>Raymond Koh say his email [EMAIL_START] raymon...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text\n",
              "496  Patrick Loh boasting about his email [EMAIL_ST...\n",
              "497  Jasmine Yeo got sian when someone spell her em...\n",
              "498  Bobby Tan write his email [EMAIL_START] bobby....\n",
              "499  Kamala Singh telling the IT guy her email [EMA...\n",
              "500  Raymond Koh say his email [EMAIL_START] raymon..."
            ]
          },
          "execution_count": 298,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_ref.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the model (Vosk)\n",
        "\n",
        "Unfortunately, there are no current models that are tuned for Singaporean English (Singlish). As such, we shall use the `vosk-model-en-us-0.42-gigaspeech` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=8\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
            "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
            "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from models/vosk-model-en-us-0.42-gigaspeech/ivector/final.ie\n",
            "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
            "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:279) Loading HCLG from models/vosk-model-en-us-0.42-gigaspeech/graph/HCLG.fst\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:294) Loading words from models/vosk-model-en-us-0.42-gigaspeech/graph/words.txt\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo models/vosk-model-en-us-0.42-gigaspeech/graph/phones/word_boundary.int\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading subtract G.fst model from models/vosk-model-en-us-0.42-gigaspeech/rescore/G.fst\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:312) Loading CARPA model from models/vosk-model-en-us-0.42-gigaspeech/rescore/G.carpa\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:318) Loading RNNLM model from models/vosk-model-en-us-0.42-gigaspeech/rnnlm/final.raw\n"
          ]
        }
      ],
      "source": [
        "from vosk import Model, KaldiRecognizer\n",
        "import soundfile as sf\n",
        "import json\n",
        "\n",
        "# Load model (replace path with your model directory)\n",
        "model_path = \"models/vosk-model-en-us-0.42-gigaspeech\"\n",
        "model = Model(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Read Audio (With just one sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So here, several things are happening:\n",
        "\n",
        "1. We create a `KaldiRecognizer` instance and set `.SetWords()` to `True`, which means that we will get word-level timestamps.\n",
        "2. The `.AcceptWaveform()` method is used to process the waveform\n",
        "3. The `.FinalResult()` method is finally called to retrieve the word-level timestamps (transcribed from the Vosk Model - although with some innacurracies, as Vosk is not a full-fledged ASR model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test on one audio sample (Simple example with Name and Email PIIs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 448,
      "metadata": {},
      "outputs": [],
      "source": [
        "audio_path = \"data/Audio_Files_for_testing/id1.wav\"\n",
        "audio_data, sample_rate = sf.read(audio_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 449,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample = run_vosk(audio_path, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 450,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'result': [{'conf': 1.0, 'end': 0.69, 'start': 0.51, 'word': 'the'},\n",
              "  {'conf': 1.0, 'end': 0.87, 'start': 0.69, 'word': 'day'},\n",
              "  {'conf': 1.0, 'end': 1.2, 'start': 0.87, 'word': 'before'},\n",
              "  {'conf': 1.0, 'end': 1.68, 'start': 1.2, 'word': 'yesterday'},\n",
              "  {'conf': 0.561098, 'end': 2.04, 'start': 1.74, 'word': 'ram'},\n",
              "  {'conf': 1.0, 'end': 2.46, 'start': 2.04, 'word': 'received'},\n",
              "  {'conf': 1.0, 'end': 2.88, 'start': 2.49, 'word': 'another'},\n",
              "  {'conf': 1.0, 'end': 3.27, 'start': 2.94, 'word': 'email'},\n",
              "  {'conf': 1.0, 'end': 3.6, 'start': 3.27, 'word': 'from'},\n",
              "  {'conf': 0.92733, 'end': 4.110592, 'start': 3.69, 'word': 'ahri'},\n",
              "  {'conf': 0.682733, 'end': 4.29, 'start': 4.110592, 'word': 'and'},\n",
              "  {'conf': 0.996653, 'end': 4.74, 'start': 4.540672, 'word': 'it'},\n",
              "  {'conf': 0.996653, 'end': 5.16, 'start': 4.95, 'word': 'club'},\n",
              "  {'conf': 0.999769, 'end': 5.43, 'start': 5.16, 'word': 'dot'},\n",
              "  {'conf': 0.997014, 'end': 5.64, 'start': 5.46, 'word': 'is'},\n",
              "  {'conf': 0.999999, 'end': 5.94, 'start': 5.64, 'word': 'g'}],\n",
              " 'text': 'the day before yesterday ram received another email from ahri and it club dot is g'}"
            ]
          },
          "execution_count": 450,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reference Transcript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 451,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The day before [DATE_START] yesterday, [DATE_END] [PERSON_START] Ram [PERSON_END] received another email from [EMAIL_START] r e m y at outlook dot sg [EMAIL_END]'"
            ]
          },
          "execution_count": 451,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_ref['text'].iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Align method usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 452,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current token: The\n",
            "Current token: day\n",
            "Current token: before\n",
            "Current token: [DATE_START]\n",
            "Current token: yesterday,\n",
            "Current token: [DATE_END]\n",
            "Current token: [PERSON_START]\n",
            "Current token: Ram\n",
            "Current token: [PERSON_END]\n",
            "Current token: received\n",
            "Current token: another\n",
            "Current token: email\n",
            "Current token: from\n",
            "Current token: [EMAIL_START]\n",
            "Current token: r\n",
            "Current token: e\n",
            "Current token: m\n",
            "Current token: y\n",
            "Current token: at\n",
            "Current token: outlook\n",
            "Current token: dot\n",
            "Current token: sg\n",
            "Current token: [EMAIL_END]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'word': 'The', 'start': 0.51, 'end': 0.69},\n",
              " {'word': 'day', 'start': 0.69, 'end': 0.87},\n",
              " {'word': 'before', 'start': 0.87, 'end': 1.2},\n",
              " {'word': '[DATE_START] y e s t e r d a y [DATE_END]',\n",
              "  'start': 1.2,\n",
              "  'end': 1.68},\n",
              " {'word': '[PERSON_START] r a m [PERSON_END]', 'start': 1.74, 'end': 2.04},\n",
              " {'word': 'received', 'start': 2.04, 'end': 2.46},\n",
              " {'word': 'another', 'start': 2.49, 'end': 2.88},\n",
              " {'word': 'email', 'start': 2.94, 'end': 3.27},\n",
              " {'word': 'from', 'start': 3.27, 'end': 3.6},\n",
              " {'word': '[EMAIL_START] r e m y a t o u t l o o k d o t s g [EMAIL_END]',\n",
              "  'start': 3.69,\n",
              "  'end': 5.94}]"
            ]
          },
          "execution_count": 452,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "align_transcript_with_vosk(sample['result'], test_set_ref['text'].iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test on one audio sample (Numerical PIIs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 453,
      "metadata": {},
      "outputs": [],
      "source": [
        "audio_path = \"data/Audio_Files_for_testing/id50.wav\"\n",
        "audio_data, sample_rate = sf.read(audio_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 454,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample2 = run_vosk(audio_path, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 455,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'result': [{'conf': 0.551495, 'end': 1.08, 'start': 0.48, 'word': 'museum'},\n",
              "  {'conf': 1.0, 'end': 1.62, 'start': 1.14, 'word': 'glimpse'},\n",
              "  {'conf': 1.0, 'end': 1.8, 'start': 1.65, 'word': 'the'},\n",
              "  {'conf': 1.0, 'end': 2.13, 'start': 1.8, 'word': 'credit'},\n",
              "  {'conf': 1.0, 'end': 2.34, 'start': 2.13, 'word': 'card'},\n",
              "  {'conf': 1.0, 'end': 3.03, 'start': 2.34, 'word': 'information'},\n",
              "  {'conf': 1.0, 'end': 3.48, 'start': 3.3, 'word': 'and'},\n",
              "  {'conf': 1.0, 'end': 3.63, 'start': 3.48, 'word': 'it'},\n",
              "  {'conf': 1.0, 'end': 3.78, 'start': 3.63, 'word': 'is'},\n",
              "  {'conf': 1.0, 'end': 4.02, 'start': 3.78, 'word': 'from'},\n",
              "  {'conf': 0.810728, 'end': 4.38, 'start': 4.02, 'word': 'visa'},\n",
              "  {'conf': 0.886088, 'end': 4.77, 'start': 4.41, 'word': 'card'},\n",
              "  {'conf': 1.0, 'end': 5.25, 'start': 5.04, 'word': 'and'},\n",
              "  {'conf': 1.0, 'end': 5.73, 'start': 5.25, 'word': 'numbered'},\n",
              "  {'conf': 1.0, 'end': 6.48, 'start': 6.15, 'word': 'eight'},\n",
              "  {'conf': 1.0, 'end': 6.81, 'start': 6.48, 'word': 'eight'},\n",
              "  {'conf': 1.0, 'end': 7.2, 'start': 6.84, 'word': 'eight'},\n",
              "  {'conf': 1.0, 'end': 7.47, 'start': 7.2, 'word': 'eight'},\n",
              "  {'conf': 1.0, 'end': 8.04, 'start': 7.62, 'word': 'four'},\n",
              "  {'conf': 0.904194, 'end': 8.28, 'start': 8.04, 'word': 'two'},\n",
              "  {'conf': 0.9962, 'end': 8.64, 'start': 8.28, 'word': 'four'},\n",
              "  {'conf': 1.0, 'end': 9.0, 'start': 8.64, 'word': 'nine'},\n",
              "  {'conf': 1.0, 'end': 9.54, 'start': 9.18, 'word': 'nine'},\n",
              "  {'conf': 0.992675, 'end': 9.81, 'start': 9.54, 'word': 'four'},\n",
              "  {'conf': 0.917958, 'end': 10.02, 'start': 9.81, 'word': 'two'},\n",
              "  {'conf': 1.0, 'end': 10.44, 'start': 10.02, 'word': 'seven'},\n",
              "  {'conf': 1.0, 'end': 10.95, 'start': 10.65, 'word': 'one'},\n",
              "  {'conf': 1.0, 'end': 11.25, 'start': 10.95, 'word': 'zero'},\n",
              "  {'conf': 1.0, 'end': 11.46, 'start': 11.25, 'word': 'one'},\n",
              "  {'conf': 0.913955, 'end': 11.61, 'start': 11.46, 'word': 'nine'}],\n",
              " 'text': 'museum glimpse the credit card information and it is from visa card and numbered eight eight eight eight four two four nine nine four two seven one zero one nine'}"
            ]
          },
          "execution_count": 455,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 456,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[PERSON_START] Raam [PERSON_END] glimpsed the credit card information and it is from [ORG_START] VISA [ORG_END] card and number [CREDIT_CARD_START] 8888-4249-9427-1019 [CREDIT_CARD_END]'"
            ]
          },
          "execution_count": 456,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_ref['text'].iloc[49]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Force align"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "credit_card, car_plate, bank_account, nric, phone, passport_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 463,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current token: [PERSON_START]\n",
            "Current token: Raam\n",
            "Current token: [PERSON_END]\n",
            "Current token: glimpsed\n",
            "Current token: the\n",
            "Current token: credit\n",
            "Current token: card\n",
            "Current token: information\n",
            "Current token: and\n",
            "Current token: it\n",
            "Current token: is\n",
            "Current token: from\n",
            "Current token: [ORG_START]\n",
            "Current token: VISA\n",
            "Current token: [ORG_END]\n",
            "Current token: card\n",
            "Current token: and\n",
            "Current token: number\n",
            "Current token: [CREDIT_CARD_START]\n",
            "Current token: 8888-4249-9427-1019\n",
            "Current token: 8\n",
            "Current token: 8\n",
            "Current token: 8\n",
            "Current token: 4\n",
            "Current token: 2\n",
            "Current token: 4\n",
            "Current token: 9\n",
            "Current token: 9\n",
            "Current token: 4\n",
            "Current token: 2\n",
            "Current token: 7\n",
            "Current token: 1\n",
            "Current token: 0\n",
            "Current token: 1\n",
            "Current token: 9\n",
            "Current token: [CREDIT_CARD_END]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'word': '[PERSON_START] r a a m [PERSON_END]', 'start': 0.48, 'end': 1.08},\n",
              " {'word': 'glimpsed', 'start': 1.14, 'end': 1.62},\n",
              " {'word': 'the', 'start': 1.65, 'end': 1.8},\n",
              " {'word': 'credit', 'start': 1.8, 'end': 2.13},\n",
              " {'word': 'card', 'start': 2.13, 'end': 2.34},\n",
              " {'word': 'information', 'start': 2.34, 'end': 3.03},\n",
              " {'word': 'and', 'start': 3.3, 'end': 3.48},\n",
              " {'word': 'it', 'start': 3.48, 'end': 3.63},\n",
              " {'word': 'is', 'start': 3.63, 'end': 3.78},\n",
              " {'word': 'from', 'start': 3.78, 'end': 4.02},\n",
              " {'word': '[ORG_START] v i s a [ORG_END]', 'start': 4.02, 'end': 4.38},\n",
              " {'word': 'card', 'start': 4.41, 'end': 4.77},\n",
              " {'word': 'and', 'start': 5.04, 'end': 5.25},\n",
              " {'word': 'number', 'start': 5.25, 'end': 5.73},\n",
              " {'word': '[CREDIT_CARD_START] 8 8 8 8 4 2 4 9 9 4 2 7 1 0 1 9 8 8 8 4 2 4 9 9 4 2 7 1 0 1 9 [CREDIT_CARD_END]',\n",
              "  'start': 6.15,\n",
              "  'end': 11.61}]"
            ]
          },
          "execution_count": 463,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "align_transcript_with_vosk(sample2['result'], test_set_ref['text'].iloc[49])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Heuristics for Forced-Alignment\n",
        "\n",
        "1. **General Matching**:\n",
        "   - The system aligns reference tokens with Vosk output by directly matching words and their timestamps.\n",
        "\n",
        "2. **Flattening Numbers**:\n",
        "   - For entities with alphanumeric characters (e.g., credit cards, phone numbers, passport numbers, car plates, etc.), the system retains the start time of the first token and the end time of the last token, without converting words to numbers.\n",
        "   \n",
        "3. **Special Cases**:\n",
        "   - **Text-based Entities**: Entities like names or organizations are matched normally without changes.\n",
        "   - **Number-based Entities**: For entities like `credit_card`, `car_plate`, `bank_account`, `nric`, `phone`, `passport_num`, the system:\n",
        "     - Removes special characters (e.g., hyphens or spaces).\n",
        "     - Splits the token into individual characters.\n",
        "     - Modifies the token list to reflect these splits while retaining the entity’s timestamps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Read Audio (All 500 samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [Archived]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import tempfile\n",
        "from pydub import AudioSegment\n",
        "from vosk import Model, KaldiRecognizer\n",
        "model_path = \"vosk-model-en-us-0.42-gigaspeech\" #model_new\"\n",
        "model = Model(model_path)\n",
        "def align_audio_with_text(audio_path, transcription):\n",
        "    audio = AudioSegment.from_wav(audio_path)\n",
        "    recognizer = KaldiRecognizer(model, audio.frame_rate)\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as temp_wav:\n",
        "        temp_wav_path = temp_wav.name\n",
        "        audio.export(temp_wav_path, format=\"wav\")\n",
        "    results = []\n",
        "    try:\n",
        "        with open(temp_wav_path, \"rb\") as wf:\n",
        "            wf.read(44)\n",
        "            recognizer.SetWords(True)\n",
        "            while True:\n",
        "                data = wf.read(4000)\n",
        "                if len(data) == 0:\n",
        "                    break\n",
        "                if recognizer.AcceptWaveform(data):\n",
        "                    results.append(json.loads(recognizer.Result()))\n",
        "            results.append(json.loads(recognizer.FinalResult()))\n",
        "    finally:\n",
        "        if os.path.exists(temp_wav_path):\n",
        "            os.remove(temp_wav_path)\n",
        "    words = []\n",
        "    for result in results:\n",
        "        if 'result' in result:\n",
        "            for word in result['result']:\n",
        "                words.append(word)\n",
        "    aligned_segments = []\n",
        "    for word in words:\n",
        "        aligned_segments.append({\n",
        "            \"start\": word[\"start\"],\n",
        "            \"end\": word[\"end\"],\n",
        "            \"word\": word[\"word\"]\n",
        "        })\n",
        "    return aligned_segments\n",
        "\n",
        "audio_dir = \"/content/drive/MyDrive/Share/Research/speechNER/finetune/Audio_Files_for_testing\"\n",
        "transcription_file = \"/content/drive/MyDrive/Share/Research/speechNER/Alignement_data/Text_with_ids_temp_preprocessed.jsonl\"\n",
        "output_file = \"/content/drive/MyDrive/Share/Research/speechNER/Alignement_data/tr_aligned_data_new.jsonl\"\n",
        "with open(transcription_file, 'r') as f:\n",
        "    transcriptions = [json.loads(line) for line in f]\n",
        "aligned_data = []\n",
        "for item in transcriptions:\n",
        "    audio_path = f\"{audio_dir}/id{item['id']}.wav\"\n",
        "    aligned_transcription = align_audio_with_text(audio_path, item['text'])\n",
        "    aligned_data.append({\n",
        "        \"id\": item['id'],\n",
        "        \"text\": item['text'],\n",
        "        \"align\": aligned_transcription\n",
        "    })\n",
        "with open(output_file, 'w') as f:\n",
        "    for item in aligned_data:\n",
        "        f.write(json.dumps(item) + '\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
